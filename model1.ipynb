{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d253976",
   "metadata": {},
   "source": [
    "1. Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a438bfaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing data from: c:\\Users\\Bharat\\Audio-Deepfake-Detection-using-Pretrained-Model\\ASVspoof 2015 DS_10283_853\\wav\n",
      "Using protocol: c:\\Users\\Bharat\\Audio-Deepfake-Detection-using-Pretrained-Model\\ASVspoof 2015 DS_10283_853\\CM_protocol\\cm_train.trn\n",
      "Loading labels from: c:\\Users\\Bharat\\Audio-Deepfake-Detection-using-Pretrained-Model\\ASVspoof 2015 DS_10283_853\\CM_protocol\\cm_train.trn\n",
      "Scanning for files in c:\\Users\\Bharat\\Audio-Deepfake-Detection-using-Pretrained-Model\\ASVspoof 2015 DS_10283_853\\wav...\n",
      "Found 16375 audio files in 'T' folders. Processing...\n",
      "Data Loaded. X shape: (16375, 128, 400, 1), y shape: (16375,)\n",
      "SUCCESS: Saved X.npy and y.npy\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "FIXED_WIDTH = 400  # Adjust as needed for your model input\n",
    "\n",
    "def audio_to_spectrogram(file_path):\n",
    "    \"\"\" Converts audio file to a spectrogram \"\"\"\n",
    "    y, sr = librosa.load(file_path, sr=None)\n",
    "    spec = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128)\n",
    "    \n",
    "    # Convert to dB\n",
    "    spec_db = librosa.power_to_db(spec, ref=np.max)\n",
    "\n",
    "    # Resize spectrogram to a fixed width (pad or truncate)\n",
    "    if spec_db.shape[1] < FIXED_WIDTH:\n",
    "        pad_width = FIXED_WIDTH - spec_db.shape[1]\n",
    "        spec_db = np.pad(spec_db, ((0, 0), (0, pad_width)), mode='constant')\n",
    "    else:\n",
    "        spec_db = spec_db[:, :FIXED_WIDTH]\n",
    "\n",
    "    return spec_db\n",
    "\n",
    "def load_labels_from_protocol(protocol_path):\n",
    "    \"\"\" Reads ASVspoof protocol file and returns a dictionary: {'filename': label} \"\"\"\n",
    "    labels = {}\n",
    "    print(f\"Loading labels from: {protocol_path}\")\n",
    "    \n",
    "    with open(protocol_path, 'r') as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            # ASVspoof 2015 format: speaker | filename | system | key\n",
    "            if len(parts) >= 4:\n",
    "                filename = parts[1]\n",
    "                key = parts[3]  # 'human' or 'spoof'\n",
    "                \n",
    "                # Label 1 for human (real), 0 for spoof\n",
    "                labels[filename] = 1 if key == 'human' else 0\n",
    "    return labels\n",
    "\n",
    "def load_dataset(dataset_path, protocol_path, max_files=None):\n",
    "    spectrograms, final_labels = [], []\n",
    "    \n",
    "    # 1. Load labels first\n",
    "    file_labels = load_labels_from_protocol(protocol_path)\n",
    "    \n",
    "    # 2. Recursively find all .wav files in all subfolders (T1, T2, etc.)\n",
    "    all_files = []\n",
    "    print(f\"Scanning for files in {dataset_path}...\")\n",
    "    \n",
    "    for root, dirs, files in os.walk(dataset_path):\n",
    "        # Only scan T* folders (training data)\n",
    "        # This modifies the walk in-place to only descend into folders starting with 'T'\n",
    "        dirs[:] = [d for d in dirs if d.startswith('T')]\n",
    "        \n",
    "        for file in files:\n",
    "            if file.endswith(\".wav\"):\n",
    "                # We store the full path to load it, and the filename to look up the label\n",
    "                all_files.append(os.path.join(root, file))\n",
    "\n",
    "    if max_files:\n",
    "        all_files = all_files[:max_files]\n",
    "        \n",
    "    print(f\"Found {len(all_files)} audio files in 'T' folders. Processing...\")\n",
    "\n",
    "    for file_path in all_files:\n",
    "        # Extract just the filename without extension (e.g., \"train_00001\" from \"wav/T1/train_00001.wav\")\n",
    "        file_name = os.path.basename(file_path)\n",
    "        file_name_no_ext = os.path.splitext(file_name)[0]\n",
    "        \n",
    "        # Only process if we have a label for this file\n",
    "        if file_name_no_ext in file_labels:\n",
    "            try:\n",
    "                spec = audio_to_spectrogram(file_path)\n",
    "                spectrograms.append(spec)\n",
    "                final_labels.append(file_labels[file_name_no_ext])\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {file_name}: {e}\")\n",
    "        # Note: We skip files that don't have a label (often hidden files or mismatching protocol)\n",
    "\n",
    "    # Convert to numpy arrays\n",
    "    if len(spectrograms) == 0:\n",
    "        print(\"ERROR: No valid data found! Check your paths and protocol file.\")\n",
    "        return np.array([]), np.array([])\n",
    "\n",
    "    X = np.array(spectrograms)[..., np.newaxis]\n",
    "    y = np.array(final_labels)\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # --- CONFIGURATION (Based on your previous findings) ---\n",
    "    \n",
    "    dataset_folder = r\"c:\\Users\\Bharat\\Audio-Deepfake-Detection-using-Pretrained-Model\\ASVspoof 2015 DS_10283_853\\wav\"\n",
    "    protocol_file = r\"c:\\Users\\Bharat\\Audio-Deepfake-Detection-using-Pretrained-Model\\ASVspoof 2015 DS_10283_853\\CM_protocol\\cm_train.trn\"\n",
    "    \n",
    "    # ---------------------\n",
    "\n",
    "    print(f\"Processing data from: {dataset_folder}\")\n",
    "    print(f\"Using protocol: {protocol_file}\")\n",
    "\n",
    "    if os.path.exists(dataset_folder) and os.path.exists(protocol_file):\n",
    "        # Set max_files=None to process the entire dataset\n",
    "        X, y = load_dataset(dataset_folder, protocol_file, max_files=None) \n",
    "        \n",
    "        if X.size > 0:\n",
    "            print(f\"Data Loaded. X shape: {X.shape}, y shape: {y.shape}\")\n",
    "            np.save(\"X.npy\", X)\n",
    "            np.save(\"y.npy\", y)\n",
    "            print(\"SUCCESS: Saved X.npy and y.npy\")\n",
    "        else:\n",
    "            print(\"ERROR: No data was loaded. Check if the folders are empty.\")\n",
    "    else:\n",
    "        print(\"Error: Paths not found despite the check.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec71165",
   "metadata": {},
   "source": [
    "2. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "85236079",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Loaded X: (16375, 128, 400, 1), y: (16375,)\n",
      "Converting grayscale to 3-channel RGB...\n",
      "Building model with input shape: (128, 400, 3)\n",
      "Starting training... (This may take a while)\n",
      "Epoch 1/10\n",
      "410/410 [==============================] - 644s 2s/step - loss: 0.5151 - accuracy: 0.7711 - val_loss: 0.4874 - val_accuracy: 0.7615\n",
      "Epoch 2/10\n",
      "410/410 [==============================] - 615s 2s/step - loss: 0.4781 - accuracy: 0.7736 - val_loss: 0.4646 - val_accuracy: 0.7618\n",
      "Epoch 3/10\n",
      "410/410 [==============================] - 599s 1s/step - loss: 0.4579 - accuracy: 0.7795 - val_loss: 0.4420 - val_accuracy: 0.7728\n",
      "Epoch 4/10\n",
      "410/410 [==============================] - 598s 1s/step - loss: 0.4421 - accuracy: 0.7873 - val_loss: 0.4305 - val_accuracy: 0.7847\n",
      "Epoch 5/10\n",
      "410/410 [==============================] - 596s 1s/step - loss: 0.4309 - accuracy: 0.7916 - val_loss: 0.4207 - val_accuracy: 0.7933\n",
      "Epoch 6/10\n",
      "410/410 [==============================] - 593s 1s/step - loss: 0.4205 - accuracy: 0.7982 - val_loss: 0.4082 - val_accuracy: 0.7991\n",
      "Epoch 7/10\n",
      "410/410 [==============================] - 592s 1s/step - loss: 0.4153 - accuracy: 0.7997 - val_loss: 0.3992 - val_accuracy: 0.8046\n",
      "Epoch 8/10\n",
      "410/410 [==============================] - 592s 1s/step - loss: 0.4050 - accuracy: 0.8077 - val_loss: 0.3903 - val_accuracy: 0.8095\n",
      "Epoch 9/10\n",
      "410/410 [==============================] - 587s 1s/step - loss: 0.3992 - accuracy: 0.8108 - val_loss: 0.3886 - val_accuracy: 0.8082\n",
      "Epoch 10/10\n",
      "410/410 [==============================] - 587s 1s/step - loss: 0.3948 - accuracy: 0.8129 - val_loss: 0.3766 - val_accuracy: 0.8186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Bharat\\anaconda3\\envs\\adf_env\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUCCESS: Model saved as deepfake_detector.h5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "\n",
    "def build_model(input_shape):\n",
    "    \"\"\" Build a deepfake detection model using EfficientNetB0 \"\"\"\n",
    "    print(f\"Building model with input shape: {input_shape}\")\n",
    "    \n",
    "    # Load pre-trained EfficientNetB0\n",
    "    # include_top=False means we cut off the final classification layer\n",
    "    # weights='imagenet' uses weights learned from real-world images\n",
    "    base_model = tf.keras.applications.EfficientNetB0(\n",
    "        input_shape=input_shape, \n",
    "        include_top=False, \n",
    "        weights='imagenet'\n",
    "    )\n",
    "    \n",
    "    # Freeze base model to keep pre-trained features (speeds up training)\n",
    "    base_model.trainable = False  \n",
    "    \n",
    "    # Add our own custom layers for audio spoof detection\n",
    "    model = models.Sequential([\n",
    "        base_model,\n",
    "        layers.GlobalAveragePooling2D(),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dropout(0.5),                    # Prevents overfitting\n",
    "        layers.Dense(1, activation='sigmoid')   # Output: 0=Spoof, 1=Bonafide\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 1. Load the data generated by preprocess.py\n",
    "    print(\"Loading data...\")\n",
    "    if not os.path.exists(\"X.npy\") or not os.path.exists(\"y.npy\"):\n",
    "        print(\"Error: X.npy or y.npy not found. Run preprocess.py first!\")\n",
    "        exit()\n",
    "\n",
    "    X = np.load(\"X.npy\")\n",
    "    y = np.load(\"y.npy\")\n",
    "\n",
    "    print(f\"Loaded X: {X.shape}, y: {y.shape}\")\n",
    "\n",
    "    # 2. Convert 1-channel grayscale to 3-channel RGB\n",
    "    # EfficientNet was trained on color images, so it expects 3 channels.\n",
    "    if X.shape[-1] == 1:\n",
    "        print(\"Converting grayscale to 3-channel RGB...\")\n",
    "        X = np.repeat(X, 3, axis=-1)\n",
    "\n",
    "    # 3. Split into Train (80%) and Validation (20%)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # 4. Build and Train\n",
    "    # input_shape will be (128, 400, 3)\n",
    "    model = build_model(input_shape=X.shape[1:])\n",
    "    \n",
    "    print(\"Starting training... (This may take a while)\")\n",
    "    history = model.fit(\n",
    "        X_train, y_train, \n",
    "        epochs=10, \n",
    "        batch_size=32, \n",
    "        validation_data=(X_test, y_test)\n",
    "    )\n",
    "    \n",
    "    # 5. Save the final model\n",
    "    model.save(\"deepfake_detector.h5\")\n",
    "    print(\"SUCCESS: Model saved as deepfake_detector.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b02330",
   "metadata": {},
   "source": [
    "3. Evaluate on Development data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820fc8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One by one processing\n",
    "'''\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import librosa\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "# We use the paths we discovered earlier\n",
    "DATASET_FOLDER = r\"c:\\Users\\Bharat\\Audio-Deepfake-Detection-using-Pretrained-Model\\ASVspoof 2015 DS_10283_853\\wav\"\n",
    "PROTOCOL_FILE  = r\"c:\\Users\\Bharat\\Audio-Deepfake-Detection-using-Pretrained-Model\\ASVspoof 2015 DS_10283_853\\CM_protocol\\cm_develop.ndx\"\n",
    "MODEL_FILE     = \"deepfake_detector.h5\"\n",
    "\n",
    "FIXED_WIDTH = 400\n",
    "\n",
    "def audio_to_spectrogram(file_path):\n",
    "    \"\"\" Converts audio file to a spectrogram (Same as preprocess.py) \"\"\"\n",
    "    y, sr = librosa.load(file_path, sr=None)\n",
    "    spec = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128)\n",
    "    spec_db = librosa.power_to_db(spec, ref=np.max)\n",
    "\n",
    "    if spec_db.shape[1] < FIXED_WIDTH:\n",
    "        pad_width = FIXED_WIDTH - spec_db.shape[1]\n",
    "        spec_db = np.pad(spec_db, ((0, 0), (0, pad_width)), mode='constant')\n",
    "    else:\n",
    "        spec_db = spec_db[:, :FIXED_WIDTH]\n",
    "\n",
    "    # IMPORTANT: Model expects (128, 400, 3), but this generates (128, 400)\n",
    "    # We add dimensions to match:\n",
    "    spec_db = spec_db[..., np.newaxis]       # (128, 400, 1)\n",
    "    spec_db = np.repeat(spec_db, 3, axis=-1) # (128, 400, 3)\n",
    "    \n",
    "    return spec_db\n",
    "\n",
    "def load_labels(protocol_path):\n",
    "    labels = {}\n",
    "    print(f\"Loading labels from: {protocol_path}\")\n",
    "    with open(protocol_path, \"r\") as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) >= 4:\n",
    "                file_name = parts[1]\n",
    "                label = 1 if parts[3] == \"human\" else 0\n",
    "                labels[file_name] = label\n",
    "    return labels\n",
    "\n",
    "def find_all_wav_files(root_folder):\n",
    "    \"\"\" Creates a dictionary {filename: full_path} for quick lookup \"\"\"\n",
    "    print(f\"Indexing audio files in {root_folder}...\")\n",
    "    file_map = {}\n",
    "    for root, dirs, files in os.walk(root_folder):\n",
    "        for file in files:\n",
    "            if file.endswith(\".wav\"):\n",
    "                # Store \"train_00001\" -> \"path/to/train_00001.wav\"\n",
    "                name_no_ext = os.path.splitext(file)[0]\n",
    "                file_map[name_no_ext] = os.path.join(root, file)\n",
    "    return file_map\n",
    "\n",
    "def evaluate_model():\n",
    "    # 1. Load Model\n",
    "    if not os.path.exists(MODEL_FILE):\n",
    "        print(\"Error: Model file not found. Run train.py first.\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Loading model: {MODEL_FILE}...\")\n",
    "    model = tf.keras.models.load_model(MODEL_FILE)\n",
    "\n",
    "    # 2. Load Labels and File Map\n",
    "    if not os.path.exists(PROTOCOL_FILE):\n",
    "        print(f\"Error: Protocol file not found at {PROTOCOL_FILE}\")\n",
    "        print(\"Check if 'cm_develop.trn' exists or change it to 'cm_evaluation.trn'\")\n",
    "        return\n",
    "\n",
    "    labels = load_labels(PROTOCOL_FILE)\n",
    "    file_map = find_all_wav_files(DATASET_FOLDER)\n",
    "\n",
    "    print(f\"Found {len(labels)} labels in protocol.\")\n",
    "    print(f\"Found {len(file_map)} wav files on disk.\")\n",
    "\n",
    "    # 3. Predict\n",
    "    predictions = []\n",
    "    actuals = []\n",
    "    \n",
    "    print(\"\\nStarting Evaluation...\")\n",
    "    # Process files listed in the protocol\n",
    "    count = 0\n",
    "    total = len(labels)\n",
    "    \n",
    "    for file_name, label in labels.items():\n",
    "        if file_name in file_map:\n",
    "            try:\n",
    "                file_path = file_map[file_name]\n",
    "                \n",
    "                # Preprocess\n",
    "                spec = audio_to_spectrogram(file_path)\n",
    "                spec = spec[np.newaxis, ...] # Add batch dimension: (1, 128, 400, 3)\n",
    "                \n",
    "                # Predict\n",
    "                pred_prob = model.predict(spec, verbose=0)[0][0]\n",
    "                pred_label = 1 if pred_prob > 0.5 else 0\n",
    "                \n",
    "                predictions.append(pred_label)\n",
    "                actuals.append(label)\n",
    "                \n",
    "                count += 1\n",
    "                if count % 100 == 0:\n",
    "                    print(f\"Processed {count}/{total} files...\", end='\\r')\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"Error reading {file_name}: {e}\")\n",
    "        else:\n",
    "            # This is common if you only downloaded the training set but protocol lists others\n",
    "            # print(f\"Missing file: {file_name}\") \n",
    "            pass\n",
    "\n",
    "    if len(predictions) == 0:\n",
    "        print(\"No predictions made. Check if your protocol filenames match your audio files.\")\n",
    "        return\n",
    "\n",
    "    # 4. Metrics\n",
    "    print(\"\\n\\n\" + \"=\"*30)\n",
    "    print(\"FINAL RESULTS\")\n",
    "    print(\"=\"*30)\n",
    "    print(f\"Accuracy:  {accuracy_score(actuals, predictions):.4f}\")\n",
    "    print(f\"Precision: {precision_score(actuals, predictions):.4f}\")\n",
    "    print(f\"Recall:    {recall_score(actuals, predictions):.4f}\")\n",
    "    print(f\"F1 Score:  {f1_score(actuals, predictions):.4f}\")\n",
    "    print(\"=\"*30)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    evaluate_model()\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0172e9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model: deepfake_detector.h5...\n",
      "Loading labels from: c:\\Users\\Bharat\\Audio-Deepfake-Detection-using-Pretrained-Model\\ASVspoof 2015 DS_10283_853\\CM_protocol\\cm_develop.ndx\n",
      "Indexing audio files in c:\\Users\\Bharat\\Audio-Deepfake-Detection-using-Pretrained-Model\\ASVspoof 2015 DS_10283_853\\wav...\n",
      "Protocol has 53372 files.\n",
      "Found 291931 .wav files on disk.\n",
      "\n",
      "Starting Fast Evaluation (Batch Size: 64)...\n",
      "Processed 52480/53372 (21.7 files/sec)...\n",
      "==============================\n",
      "FINAL RESULTS\n",
      "==============================\n",
      "Accuracy:  0.8812\n",
      "Precision: 0.2196\n",
      "Recall:    0.3186\n",
      "F1 Score:  0.2600\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "# (with Batching)\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import librosa\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import time\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "BASE_PATH = r\"c:\\Users\\Bharat\\Audio-Deepfake-Detection-using-Pretrained-Model\\ASVspoof 2015 DS_10283_853\"\n",
    "DATASET_FOLDER = os.path.join(BASE_PATH, \"wav\")\n",
    "\n",
    "# Use 'cm_evaluation.ndx' for the final test, or 'cm_develop.ndx' for dev\n",
    "PROTOCOL_FILE = os.path.join(BASE_PATH, \"CM_protocol\", \"cm_develop.ndx\") \n",
    "\n",
    "MODEL_FILE  = \"deepfake_detector.h5\"\n",
    "FIXED_WIDTH = 400\n",
    "BATCH_SIZE  = 256  # Process 64 files at once (Much faster)\n",
    "\n",
    "def audio_to_spectrogram(file_path):\n",
    "    \"\"\" Loads audio and creates spectrogram (Optimized for failures) \"\"\"\n",
    "    try:\n",
    "        y, sr = librosa.load(file_path, sr=None)\n",
    "        spec = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128)\n",
    "        spec_db = librosa.power_to_db(spec, ref=np.max)\n",
    "\n",
    "        if spec_db.shape[1] < FIXED_WIDTH:\n",
    "            pad_width = FIXED_WIDTH - spec_db.shape[1]\n",
    "            spec_db = np.pad(spec_db, ((0, 0), (0, pad_width)), mode='constant')\n",
    "        else:\n",
    "            spec_db = spec_db[:, :FIXED_WIDTH]\n",
    "\n",
    "        spec_db = spec_db[..., np.newaxis]\n",
    "        spec_db = np.repeat(spec_db, 3, axis=-1)\n",
    "        return spec_db\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "def load_labels(protocol_path):\n",
    "    labels = {}\n",
    "    print(f\"Loading labels from: {protocol_path}\")\n",
    "    with open(protocol_path, \"r\") as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) >= 4:\n",
    "                file_name = parts[1]\n",
    "                key = parts[3]\n",
    "                label = 1 if key == \"human\" else 0\n",
    "                labels[file_name] = label\n",
    "    return labels\n",
    "\n",
    "def find_all_wav_files(root_folder):\n",
    "    print(f\"Indexing audio files in {root_folder}...\")\n",
    "    file_map = {}\n",
    "    for root, dirs, files in os.walk(root_folder):\n",
    "        for file in files:\n",
    "            if file.endswith(\".wav\"):\n",
    "                name_no_ext = os.path.splitext(file)[0]\n",
    "                file_map[name_no_ext] = os.path.join(root, file)\n",
    "    return file_map\n",
    "\n",
    "def evaluate_model():\n",
    "    if not os.path.exists(MODEL_FILE):\n",
    "        print(\"Error: deepfake_detector.h5 not found.\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Loading model: {MODEL_FILE}...\")\n",
    "    model = tf.keras.models.load_model(MODEL_FILE)\n",
    "\n",
    "    labels = load_labels(PROTOCOL_FILE)\n",
    "    file_map = find_all_wav_files(DATASET_FOLDER)\n",
    "\n",
    "    print(f\"Protocol has {len(labels)} files.\")\n",
    "    print(f\"Found {len(file_map)} .wav files on disk.\")\n",
    "\n",
    "    predictions = []\n",
    "    actuals = []\n",
    "    \n",
    "    print(\"\\nStarting Fast Evaluation (Batch Size: 64)...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Batch containers\n",
    "    batch_images = []\n",
    "    batch_labels = []\n",
    "    \n",
    "    total_files = len(labels)\n",
    "    processed_count = 0\n",
    "\n",
    "    for file_name, label in labels.items():\n",
    "        if file_name in file_map:\n",
    "            file_path = file_map[file_name]\n",
    "            spec = audio_to_spectrogram(file_path)\n",
    "            \n",
    "            if spec is not None:\n",
    "                batch_images.append(spec)\n",
    "                batch_labels.append(label)\n",
    "\n",
    "            # When batch is full, predict\n",
    "            if len(batch_images) == BATCH_SIZE:\n",
    "                # Convert list to numpy array: (64, 128, 400, 3)\n",
    "                batch_np = np.array(batch_images)\n",
    "                \n",
    "                # Predict entire batch at once\n",
    "                preds = model.predict(batch_np, verbose=0)\n",
    "                \n",
    "                # Store results\n",
    "                for p in preds:\n",
    "                    predictions.append(1 if p[0] > 0.5 else 0)\n",
    "                \n",
    "                actuals.extend(batch_labels)\n",
    "                \n",
    "                # Reset batch\n",
    "                batch_images = []\n",
    "                batch_labels = []\n",
    "                \n",
    "                processed_count += BATCH_SIZE\n",
    "                \n",
    "                # Print status every 10 batches (640 files)\n",
    "                if processed_count % 640 == 0:\n",
    "                    elapsed = time.time() - start_time\n",
    "                    rate = processed_count / elapsed\n",
    "                    print(f\"Processed {processed_count}/{total_files} ({rate:.1f} files/sec)...\", end='\\r')\n",
    "\n",
    "    # Process remaining files in the final partial batch\n",
    "    if len(batch_images) > 0:\n",
    "        batch_np = np.array(batch_images)\n",
    "        preds = model.predict(batch_np, verbose=0)\n",
    "        for p in preds:\n",
    "            predictions.append(1 if p[0] > 0.5 else 0)\n",
    "        actuals.extend(batch_labels)\n",
    "\n",
    "    # Metrics\n",
    "    print(\"\\n\" + \"=\"*30)\n",
    "    if len(predictions) > 0:\n",
    "        print(\"FINAL RESULTS\")\n",
    "        print(\"=\"*30)\n",
    "        print(f\"Accuracy:  {accuracy_score(actuals, predictions):.4f}\")\n",
    "        print(f\"Precision: {precision_score(actuals, predictions):.4f}\")\n",
    "        print(f\"Recall:    {recall_score(actuals, predictions):.4f}\")\n",
    "        print(f\"F1 Score:  {f1_score(actuals, predictions):.4f}\")\n",
    "    else:\n",
    "        print(\"No predictions made.\")\n",
    "    print(\"=\"*30)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    evaluate_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0792f8e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model: deepfake_detector.h5...\n",
      "Loading labels from: c:\\Users\\Bharat\\Audio-Deepfake-Detection-using-Pretrained-Model\\ASVspoof 2015 DS_10283_853\\CM_protocol\\cm_develop.ndx\n",
      "Indexing audio files in c:\\Users\\Bharat\\Audio-Deepfake-Detection-using-Pretrained-Model\\ASVspoof 2015 DS_10283_853\\wav...\n",
      "Protocol has 53372 files.\n",
      "Found 291931 .wav files on disk.\n",
      "\n",
      "Starting Evaluation on cm_develop.ndx...\n",
      "Processed 52480/53372 (19.0 files/sec)...\n",
      "==============================\n",
      "FINAL RESULTS\n",
      "==============================\n",
      "EER:       26.79%  <--- LOWER IS BETTER\n",
      "Accuracy:  0.8812\n",
      "Precision: 0.2196\n",
      "Recall:    0.3186\n",
      "F1 Score:  0.2600\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import librosa\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.optimize import brentq\n",
    "import time\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "BASE_PATH = r\"c:\\Users\\Bharat\\Audio-Deepfake-Detection-using-Pretrained-Model\\ASVspoof 2015 DS_10283_853\"\n",
    "DATASET_FOLDER = os.path.join(BASE_PATH, \"wav\")\n",
    "\n",
    "# !!! TARGETING DEVELOPMENT SET AS REQUESTED !!!\n",
    "PROTOCOL_FILE = os.path.join(BASE_PATH, \"CM_protocol\", \"cm_develop.ndx\")\n",
    "\n",
    "MODEL_FILE  = \"deepfake_detector.h5\"\n",
    "FIXED_WIDTH = 400\n",
    "BATCH_SIZE  = 256  # Optimized for your 16GB RAM\n",
    "\n",
    "def compute_eer(y_true, y_score):\n",
    "    \"\"\" Computes Equal Error Rate (EER) using interpolation \"\"\"\n",
    "    # roc_curve returns: false positive rate, true positive rate, thresholds\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_score, pos_label=1)\n",
    "    \n",
    "    # EER is where False Positive Rate == False Rejection Rate (1 - TPR)\n",
    "    eer = brentq(lambda x : 1. - x - interp1d(fpr, tpr)(x), 0., 1.)\n",
    "    return eer\n",
    "\n",
    "def audio_to_spectrogram(file_path):\n",
    "    try:\n",
    "        y, sr = librosa.load(file_path, sr=None)\n",
    "        spec = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128)\n",
    "        spec_db = librosa.power_to_db(spec, ref=np.max)\n",
    "\n",
    "        if spec_db.shape[1] < FIXED_WIDTH:\n",
    "            pad_width = FIXED_WIDTH - spec_db.shape[1]\n",
    "            spec_db = np.pad(spec_db, ((0, 0), (0, pad_width)), mode='constant')\n",
    "        else:\n",
    "            spec_db = spec_db[:, :FIXED_WIDTH]\n",
    "\n",
    "        spec_db = spec_db[..., np.newaxis]\n",
    "        spec_db = np.repeat(spec_db, 3, axis=-1)\n",
    "        return spec_db\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "def load_labels(protocol_path):\n",
    "    labels = {}\n",
    "    print(f\"Loading labels from: {protocol_path}\")\n",
    "    with open(protocol_path, \"r\") as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) >= 4:\n",
    "                file_name = parts[1]\n",
    "                key = parts[3]\n",
    "                label = 1 if key == \"human\" else 0\n",
    "                labels[file_name] = label\n",
    "    return labels\n",
    "\n",
    "def find_all_wav_files(root_folder):\n",
    "    print(f\"Indexing audio files in {root_folder}...\")\n",
    "    file_map = {}\n",
    "    for root, dirs, files in os.walk(root_folder):\n",
    "        for file in files:\n",
    "            if file.endswith(\".wav\"):\n",
    "                name_no_ext = os.path.splitext(file)[0]\n",
    "                file_map[name_no_ext] = os.path.join(root, file)\n",
    "    return file_map\n",
    "\n",
    "def evaluate_model():\n",
    "    if not os.path.exists(MODEL_FILE):\n",
    "        print(\"Error: deepfake_detector.h5 not found.\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Loading model: {MODEL_FILE}...\")\n",
    "    model = tf.keras.models.load_model(MODEL_FILE)\n",
    "\n",
    "    labels = load_labels(PROTOCOL_FILE)\n",
    "    file_map = find_all_wav_files(DATASET_FOLDER)\n",
    "\n",
    "    print(f\"Protocol has {len(labels)} files.\")\n",
    "    print(f\"Found {len(file_map)} .wav files on disk.\")\n",
    "\n",
    "    print(f\"\\nStarting Evaluation on {os.path.basename(PROTOCOL_FILE)}...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Batch Storage\n",
    "    batch_images = []\n",
    "    batch_labels = []\n",
    "    \n",
    "    # Results Storage\n",
    "    predictions = []       # Binary (0 or 1)\n",
    "    prediction_scores = [] # Raw Probability (0.0 to 1.0) for EER\n",
    "    actuals = []           # Ground Truth\n",
    "    \n",
    "    total_files = len(labels)\n",
    "    processed_count = 0\n",
    "\n",
    "    for file_name, label in labels.items():\n",
    "        if file_name in file_map:\n",
    "            file_path = file_map[file_name]\n",
    "            spec = audio_to_spectrogram(file_path)\n",
    "            \n",
    "            if spec is not None:\n",
    "                batch_images.append(spec)\n",
    "                batch_labels.append(label)\n",
    "\n",
    "            # When batch is full, predict\n",
    "            if len(batch_images) == BATCH_SIZE:\n",
    "                batch_np = np.array(batch_images)\n",
    "                preds = model.predict(batch_np, verbose=0)\n",
    "                \n",
    "                for p in preds:\n",
    "                    prob = p[0]\n",
    "                    prediction_scores.append(prob)       # Save raw score\n",
    "                    predictions.append(1 if prob > 0.5 else 0) # Save binary\n",
    "                \n",
    "                actuals.extend(batch_labels)\n",
    "                \n",
    "                batch_images = []\n",
    "                batch_labels = []\n",
    "                processed_count += BATCH_SIZE\n",
    "                \n",
    "                if processed_count % (BATCH_SIZE * 5) == 0:\n",
    "                    elapsed = time.time() - start_time\n",
    "                    rate = processed_count / elapsed\n",
    "                    print(f\"Processed {processed_count}/{total_files} ({rate:.1f} files/sec)...\", end='\\r')\n",
    "\n",
    "    # Process Final Batch\n",
    "    if len(batch_images) > 0:\n",
    "        batch_np = np.array(batch_images)\n",
    "        preds = model.predict(batch_np, verbose=0)\n",
    "        for p in preds:\n",
    "            prob = p[0]\n",
    "            prediction_scores.append(prob)\n",
    "            predictions.append(1 if prob > 0.5 else 0)\n",
    "        actuals.extend(batch_labels)\n",
    "\n",
    "    # --- METRICS & EER ---\n",
    "    print(\"\\n\" + \"=\"*30)\n",
    "    if len(predictions) > 0:\n",
    "        print(\"FINAL RESULTS\")\n",
    "        print(\"=\"*30)\n",
    "        \n",
    "        # Calculate EER\n",
    "        try:\n",
    "            eer = compute_eer(actuals, prediction_scores)\n",
    "            print(f\"EER:       {eer * 100:.2f}%  <--- LOWER IS BETTER\")\n",
    "        except Exception as e:\n",
    "            print(f\"EER Error: {e}\")\n",
    "\n",
    "        print(f\"Accuracy:  {accuracy_score(actuals, predictions):.4f}\")\n",
    "        print(f\"Precision: {precision_score(actuals, predictions):.4f}\")\n",
    "        print(f\"Recall:    {recall_score(actuals, predictions):.4f}\")\n",
    "        print(f\"F1 Score:  {f1_score(actuals, predictions):.4f}\")\n",
    "    else:\n",
    "        print(\"No predictions made.\")\n",
    "    print(\"=\"*30)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    evaluate_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee778fe",
   "metadata": {},
   "source": [
    "4. Evaluate on Evaluation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25cc1bc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model: deepfake_detector.h5...\n",
      "Loading labels from: c:\\Users\\Bharat\\Audio-Deepfake-Detection-using-Pretrained-Model\\ASVspoof 2015 DS_10283_853\\CM_protocol\\cm_evaluation.ndx\n",
      "Indexing audio files in c:\\Users\\Bharat\\Audio-Deepfake-Detection-using-Pretrained-Model\\ASVspoof 2015 DS_10283_853\\wav...\n",
      "Protocol has 193404 files.\n",
      "Found 291931 .wav files on disk.\n",
      "\n",
      "Starting Evaluation on cm_evaluation.ndx...\n",
      "Processed 192000/193404 (19.8 files/sec)...\n",
      "==============================\n",
      "FINAL RESULTS\n",
      "==============================\n",
      "Accuracy:  0.8581\n",
      "Precision: 0.1425\n",
      "Recall:    0.3823\n",
      "F1 Score:  0.2076\n",
      "------------------------------\n",
      "EER:       29.63%\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "# (with Batching)\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import librosa\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.optimize import brentq\n",
    "import time\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "BASE_PATH = r\"c:\\Users\\Bharat\\Audio-Deepfake-Detection-using-Pretrained-Model\\ASVspoof 2015 DS_10283_853\"\n",
    "DATASET_FOLDER = os.path.join(BASE_PATH, \"wav\")\n",
    "\n",
    "# !!! IMPORTANT !!!\n",
    "# Use 'cm_develop.ndx' to check EER on the Practice Set (Development)\n",
    "# Use 'cm_evaluation.ndx' for the Final Exam (Evaluation)\n",
    "PROTOCOL_FILE = os.path.join(BASE_PATH, \"CM_protocol\", \"cm_evaluation.ndx\")\n",
    "\n",
    "MODEL_FILE  = \"deepfake_detector.h5\"\n",
    "FIXED_WIDTH = 400\n",
    "BATCH_SIZE  = 256  # Kept high for speed\n",
    "\n",
    "def compute_eer(y_true, y_score):\n",
    "    \"\"\" Computes Equal Error Rate (EER) \"\"\"\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_score, pos_label=1)\n",
    "    eer = brentq(lambda x : 1. - x - interp1d(fpr, tpr)(x), 0., 1.)\n",
    "    return eer\n",
    "\n",
    "def audio_to_spectrogram(file_path):\n",
    "    try:\n",
    "        y, sr = librosa.load(file_path, sr=None)\n",
    "        spec = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128)\n",
    "        spec_db = librosa.power_to_db(spec, ref=np.max)\n",
    "\n",
    "        if spec_db.shape[1] < FIXED_WIDTH:\n",
    "            pad_width = FIXED_WIDTH - spec_db.shape[1]\n",
    "            spec_db = np.pad(spec_db, ((0, 0), (0, pad_width)), mode='constant')\n",
    "        else:\n",
    "            spec_db = spec_db[:, :FIXED_WIDTH]\n",
    "\n",
    "        spec_db = spec_db[..., np.newaxis]\n",
    "        spec_db = np.repeat(spec_db, 3, axis=-1)\n",
    "        return spec_db\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "def load_labels(protocol_path):\n",
    "    labels = {}\n",
    "    print(f\"Loading labels from: {protocol_path}\")\n",
    "    with open(protocol_path, \"r\") as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) >= 4:\n",
    "                file_name = parts[1]\n",
    "                key = parts[3]\n",
    "                label = 1 if key == \"human\" else 0\n",
    "                labels[file_name] = label\n",
    "    return labels\n",
    "\n",
    "def find_all_wav_files(root_folder):\n",
    "    print(f\"Indexing audio files in {root_folder}...\")\n",
    "    file_map = {}\n",
    "    for root, dirs, files in os.walk(root_folder):\n",
    "        for file in files:\n",
    "            if file.endswith(\".wav\"):\n",
    "                name_no_ext = os.path.splitext(file)[0]\n",
    "                file_map[name_no_ext] = os.path.join(root, file)\n",
    "    return file_map\n",
    "\n",
    "def evaluate_model():\n",
    "    if not os.path.exists(MODEL_FILE):\n",
    "        print(\"Error: deepfake_detector.h5 not found.\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Loading model: {MODEL_FILE}...\")\n",
    "    model = tf.keras.models.load_model(MODEL_FILE)\n",
    "\n",
    "    labels = load_labels(PROTOCOL_FILE)\n",
    "    file_map = find_all_wav_files(DATASET_FOLDER)\n",
    "\n",
    "    print(f\"Protocol has {len(labels)} files.\")\n",
    "    print(f\"Found {len(file_map)} .wav files on disk.\")\n",
    "\n",
    "    print(f\"\\nStarting Evaluation on {os.path.basename(PROTOCOL_FILE)}...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Storage\n",
    "    batch_images = []\n",
    "    batch_labels = []\n",
    "    \n",
    "    predictions = []       # Binary 0/1\n",
    "    prediction_scores = [] # Raw probabilities\n",
    "    actuals = []           # Ground truth\n",
    "    \n",
    "    total_files = len(labels)\n",
    "    processed_count = 0\n",
    "\n",
    "    for file_name, label in labels.items():\n",
    "        if file_name in file_map:\n",
    "            file_path = file_map[file_name]\n",
    "            spec = audio_to_spectrogram(file_path)\n",
    "            \n",
    "            if spec is not None:\n",
    "                batch_images.append(spec)\n",
    "                batch_labels.append(label)\n",
    "\n",
    "            # Process Batch\n",
    "            if len(batch_images) == BATCH_SIZE:\n",
    "                batch_np = np.array(batch_images)\n",
    "                preds = model.predict(batch_np, verbose=0)\n",
    "                \n",
    "                for p in preds:\n",
    "                    prob = p[0]\n",
    "                    prediction_scores.append(prob)       # Save raw score for EER\n",
    "                    predictions.append(1 if prob > 0.5 else 0) # Save binary label\n",
    "                \n",
    "                actuals.extend(batch_labels)\n",
    "                \n",
    "                batch_images = []\n",
    "                batch_labels = []\n",
    "                processed_count += BATCH_SIZE\n",
    "                \n",
    "                if processed_count % (BATCH_SIZE * 10) == 0:\n",
    "                    elapsed = time.time() - start_time\n",
    "                    rate = processed_count / elapsed\n",
    "                    print(f\"Processed {processed_count}/{total_files} ({rate:.1f} files/sec)...\", end='\\r')\n",
    "\n",
    "    # Process Final Batch\n",
    "    if len(batch_images) > 0:\n",
    "        batch_np = np.array(batch_images)\n",
    "        preds = model.predict(batch_np, verbose=0)\n",
    "        for p in preds:\n",
    "            prob = p[0]\n",
    "            prediction_scores.append(prob)\n",
    "            predictions.append(1 if prob > 0.5 else 0)\n",
    "        actuals.extend(batch_labels)\n",
    "\n",
    "    # Metrics\n",
    "    print(\"\\n\" + \"=\"*30)\n",
    "    if len(predictions) > 0:\n",
    "        # Calculate EER\n",
    "        try:\n",
    "            eer = compute_eer(actuals, prediction_scores)\n",
    "            eer_percent = eer * 100\n",
    "        except Exception as e:\n",
    "            eer_percent = -1\n",
    "            print(f\"Could not compute EER: {e}\")\n",
    "\n",
    "        print(\"FINAL RESULTS\")\n",
    "        print(\"=\"*30)\n",
    "        print(f\"Accuracy:  {accuracy_score(actuals, predictions):.4f}\")\n",
    "        print(f\"Precision: {precision_score(actuals, predictions):.4f}\")\n",
    "        print(f\"Recall:    {recall_score(actuals, predictions):.4f}\")\n",
    "        print(f\"F1 Score:  {f1_score(actuals, predictions):.4f}\")\n",
    "        print(\"-\" * 30)\n",
    "        print(f\"EER:       {eer_percent:.2f}%\")\n",
    "    else:\n",
    "        print(\"No predictions made.\")\n",
    "    print(\"=\"*30)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    evaluate_model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
