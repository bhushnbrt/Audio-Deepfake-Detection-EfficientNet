# üîä Audio Deepfake Detection using EfficientNet

![Python](https://img.shields.io/badge/Python-3.8%2B-blue)
![TensorFlow](https://img.shields.io/badge/TensorFlow-2.x-orange)
![License](https://img.shields.io/badge/License-MIT-green)

This project is an end-to-end deep learning pipeline designed to **detect AI-generated (spoof) audio** using the **ASVspoof 2015 dataset**. By converting audio into **Mel-spectrograms** and processing them with a **pretrained EfficientNetB0** model, the system discriminates between **Bonafide (Real)** and **Spoof (Deepfake)** speech with high accuracy.

---

## üìå Table of Contents
- [üîç Project Overview](#-project-overview)
- [üìä Dataset](#-dataset)
- [üß† Model Architecture](#-model-architecture)
- [üöÄ Methodology](#-methodology)
- [üìà Performance Results](#-performance-results)
- [üõ† Installation & Setup](#-installation--setup)
- [üôè Acknowledgments](#-acknowledgments)
- [‚úâÔ∏è Contact](#-contact)

---

## üîç Project Overview

As voice synthesis technology improves, distinguishing between human and machine-generated speech becomes critical for security. This project focuses on:

‚úÖ **Feature Extraction:** Converting raw audio to 3-channel Mel-spectrograms.  
‚úÖ **Deep Learning:** Fine-tuning a pretrained EfficientNetB0 CNN.  
‚úÖ **Robust Evaluation:** Testing on both known (Development) and unknown (Evaluation) attack types.  
‚úÖ **Metric Analysis:** Using Equal Error Rate (EER) to measure security performance.

---

## üìä Dataset

We utilize the **ASVspoof 2015 Dataset**, a benchmark for spoofing detection.
- **Classes:** `Bonafide` (Human) vs. `Spoof` (Text-to-Speech / Voice Conversion).
- **Data Format:** `.wav` files converted to spectrogram images.
- **Challenge:** The Evaluation set contains **5 unknown attack algorithms (S6‚ÄìS10)** that the model never saw during training, testing its generalization.

üîó **Reference:** [ASVspoof Challenge](https://www.asvspoof.org/)

---

## üß† Model Architecture

The core of the system is **EfficientNetB0**, chosen for its balance of speed and accuracy.

1.  **Input:** Mel-Spectrograms resized to `(128, 400, 3)`.
2.  **Backbone:** EfficientNetB0 (Pretrained on ImageNet, frozen weights).
3.  **Head:**
    * `GlobalAveragePooling2D`
    * `Dense(128, ReLU)`
    * `Dropout(0.5)` (To prevent overfitting)
    * `Dense(1, Sigmoid)` (Output probability)

---

## üöÄ Methodology

### 1Ô∏è‚É£ Preprocessing
- Audio is loaded using `librosa`.
- Converted to **Mel-spectrogram** (128 mel bands).
- Converted to **Decibel scale**.
- Fixed width resizing to **400 time steps** (Padding/Truncating).
- Duplicated to **3 channels** to match EfficientNet's expected input.

### 2Ô∏è‚É£ Training
- **Optimizer:** Adam (`lr=0.0001`)
- **Loss Function:** Binary Crossentropy
- **Batch Size:** 32
- **Epochs:** 10

---

## üìà Performance Results

The model was evaluated on two distinct datasets to test robustness.

| Metric | Development Set (Known Attacks) | Evaluation Set (Unknown Attacks) |
| :--- | :--- | :--- |
| **Status** | *Practice Exam* | *Final Exam* |
| **Accuracy** | **88.12%** | **85.81%** |
| **EER (Equal Error Rate)** | **26.79%** | **29.63%** |
| **F1 Score** | 0.26 | 0.21 |

> **Analysis:** The model maintains **~86% accuracy** even on unknown attacks, showing strong generalization capabilities. The low EER difference (~2.8%) between Dev and Eval sets confirms the model is not just memorizing training data.

---

## üõ† Installation & Setup

### üîß Prerequisites
* Python 3.8+
* TensorFlow
* Librosa
* Numpy, Scikit-learn, Scipy

### 1Ô∏è‚É£ Clone the Repository
```bash
git clone [https://github.com/bhushnbrt/Audio-Deepfake-Detection-EfficientNet.git](https://github.com/bhushnbrt/Audio-Deepfake-Detection-EfficientNet.git)
cd Audio-Deepfake-Detection-EfficientNet
```bash


## üôè Acknowledgments
This project was inspired by the work of [AmoghAgrawal1249](https://github.com/AmoghAgrawal1249). All implementation, development, and code are **100% original work**. The EfficientNet-based approach and methodology for audio deepfake detection have been implemented independently from scratch.

## ‚úâÔ∏è Contact
For questions or inquiries about this project, please reach out via:

- **Email:** [bhushnbrt@gmail.com]
- **GitHub:** [@bhushnbrt](https://github.com/bhushnbrt)
